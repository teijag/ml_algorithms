{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-based (Ensemble) Models and Handling Imbalanced Data [30 points]\n",
    "\n",
    "For this problem, we will use the wine quality dataset on which the task is a binary classification of whether a given wine is of low or high quality based on different physicochemical features.\n",
    "Â \n",
    "The dataset consists of a set of physicochemical features as inputs and the target is wine quality stored in the target column, where a value of 1 corresponds to an instance of high quality wine and -1 corresponds to an instance of low quality ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data (3pts)\n",
    "Load the data from library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use wine dataset from imlearn\n",
    "from imblearn.datasets import fetch_datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "datasets = fetch_datasets()\n",
    "\n",
    "# Wine quality dataset contains 12 features, descriptions found here: \n",
    "# https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
    "data = datasets['wine_quality']\n",
    "\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Draw the class distribution of the dataset. What are possible problems if we train a classification model directly on this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of high quality observations 0.03736218864842793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2fdfb908>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADdFJREFUeJzt3X+s3fVdx/HnixY2jTJgvdtYi5a4Jq6Lus2GEffPAgbKnCtZYOnipJkk9Q/ULfEX+IcojGSLKPsRtoRIRyFmHWEquJCQhh8uRgdcBBk/QqhsQgPSYvkxXIaWvf3jfAoHuL09H+z3nnu5z0dyc8/3cz7n9t2k4cn3nO85N1WFJEmTOmLaA0iSlhbDIUnqYjgkSV0MhySpi+GQJHUxHJKkLoZDktTFcEiSuhgOSVKXldMeYAirVq2qtWvXTnsMSVpS7rrrrqeqauZQ+96Q4Vi7di2zs7PTHkOSlpQk/zHJPp+qkiR1MRySpC6GQ5LUxXBIkroYDklSF8MhSepiOCRJXQyHJKmL4ZAkdXlDvnP8cPjlP7x62iNoEbrrL86Z9gjS1HnGIUnqYjgkSV0MhySpi+GQJHUxHJKkLoZDktTFcEiSuhgOSVIXwyFJ6mI4JEldDIckqYvhkCR1MRySpC6GQ5LUxXBIkroYDklSF8MhSepiOCRJXQyHJKmL4ZAkdTEckqQuhkOS1MVwSJK6GA5JUhfDIUnqYjgkSV0GD0eSFUnuTvKtdnxiktuTPJzkG0mOautvase72v1rx37GBW39oSSnDz2zJOngFuKM49PAg2PHnwcuq6p1wNPAuW39XODpqnoXcFnbR5L1wGbgPcBG4CtJVizA3JKkOQwajiRrgF8D/rodBzgFuK5t2Q6c2W5vase0+09t+zcBO6rqhar6HrALOGnIuSVJBzf0GccXgD8CftyO3wo8U1X72/FuYHW7vRp4DKDd/2zb/9L6HI+RJC2wwcKR5CPAnqq6a3x5jq11iPvme8z4n7c1yWyS2b1793bPK0mazJBnHB8EPprk+8AORk9RfQE4JsnKtmcN8Hi7vRs4AaDd/xZg3/j6HI95SVVdUVUbqmrDzMzM4f/bSJKAAcNRVRdU1ZqqWsvoxe1bquo3gFuBs9q2LcD17fYN7Zh2/y1VVW19c7vq6kRgHXDHUHNLkua38tBbDrs/BnYk+SxwN3BlW78SuCbJLkZnGpsBqur+JNcCDwD7gfOq6sWFH1uSBAsUjqq6Dbit3X6EOa6KqqofAWcf5PGXAJcMN6EkaVK+c1yS1MVwSJK6GA5JUhfDIUnqYjgkSV0MhySpi+GQJHUxHJKkLoZDktTFcEiSuhgOSVIXwyFJ6mI4JEldDIckqYvhkCR1MRySpC6GQ5LUxXBIkroYDklSF8MhSepiOCRJXQyHJKmL4ZAkdTEckqQuhkOS1MVwSJK6GA5JUhfDIUnqYjgkSV0MhySpi+GQJHUxHJKkLoZDktTFcEiSuhgOSVKXwcKR5M1J7kjyb0nuT/Lnbf3EJLcneTjJN5Ic1dbf1I53tfvXjv2sC9r6Q0lOH2pmSdKhDXnG8QJwSlX9EvBeYGOSk4HPA5dV1TrgaeDctv9c4OmqehdwWdtHkvXAZuA9wEbgK0lWDDi3JGkeg4WjRp5vh0e2rwJOAa5r69uBM9vtTe2Ydv+pSdLWd1TVC1X1PWAXcNJQc0uS5jfoaxxJViS5B9gD7AT+HXimqva3LbuB1e32auAxgHb/s8Bbx9fneIwkaYENGo6qerGq3gusYXSW8O65trXvOch9B1t/hSRbk8wmmd27d+/rHVmSdAgLclVVVT0D3AacDByTZGW7aw3weLu9GzgBoN3/FmDf+Pocjxn/M66oqg1VtWFmZmaIv4YkiWGvqppJcky7/RPArwIPArcCZ7VtW4Dr2+0b2jHt/luqqtr65nbV1YnAOuCOoeaWJM1v5aG3vG7HA9vbFVBHANdW1beSPADsSPJZ4G7gyrb/SuCaJLsYnWlsBqiq+5NcCzwA7AfOq6oXB5xbkjSPwcJRVfcC75tj/RHmuCqqqn4EnH2Qn3UJcMnhnlGS1M93jkuSuhgOSVIXwyFJ6mI4JEldDIckqYvhkCR1mSgcSW6eZE2S9MY37/s4krwZ+ElgVZJjeflzo44G3jnwbJKkRehQbwD8beAzjCJxFy+H4zng8gHnkiQtUvOGo6q+CHwxye9W1ZcXaCZJ0iI20UeOVNWXk/wKsHb8MVV19UBzSZIWqYnCkeQa4OeAe4ADHzBYgOGQpGVm0g853ACsbx9zLklaxiZ9H8d9wDuGHESStDRMesaxCnggyR3ACwcWq+qjg0wlSVq0Jg3Hnw05hCRp6Zj0qqp/HHoQSdLSMOlVVT9gdBUVwFHAkcB/V9XRQw0mSVqcJj3j+Onx4yRnMsevf5UkvfG9rk/Hraq/B045zLNIkpaASZ+q+tjY4RGM3tfhezokaRma9KqqXx+7vR/4PrDpsE8jSVr0Jn2N41NDDyJJWhom/UVOa5L8XZI9SZ5M8s0ka4YeTpK0+Ez64vjXgBsY/V6O1cA/tDVJ0jIzaThmquprVbW/fV0FzAw4lyRpkZo0HE8l+WSSFe3rk8B/DTmYJGlxmjQcvwV8HPhP4AngLMAXzCVpGZr0ctyLgS1V9TRAkuOASxkFRZK0jEx6xvGLB6IBUFX7gPcNM5IkaTGbNBxHJDn2wEE745j0bEWS9AYy6X/8/xL45yTXMfqokY8Dlww2lSRp0Zr0neNXJ5ll9MGGAT5WVQ8MOpkkaVGa+OmmFgpjIUnL3Ov6WHVJ0vI1WDiSnJDk1iQPJrk/yafb+nFJdiZ5uH0/tq0nyZeS7Epyb5L3j/2sLW3/w0m2DDWzJOnQhjzj2A/8flW9GzgZOC/JeuB84OaqWgfc3I4BzgDWta+twFfhpSu4LgQ+wOi3Dl44foWXJGlhDRaOqnqiqv613f4B8CCjD0jcBGxv27YDZ7bbm4Cra+Q7wDFJjgdOB3ZW1b72XpKdwMah5pYkzW9BXuNIspbRGwZvB95eVU/AKC7A29q21cBjYw/b3dYOti5JmoLBw5Hkp4BvAp+pqufm2zrHWs2z/uo/Z2uS2SSze/fufX3DSpIOadBwJDmSUTT+pqr+ti0/2Z6Con3f09Z3AyeMPXwN8Pg8669QVVdU1Yaq2jAz4ye+S9JQhryqKsCVwINV9Vdjd90AHLgyagtw/dj6Oe3qqpOBZ9tTWTcBpyU5tr0oflpbkyRNwZCfN/VB4DeB7ya5p639CfA54Nok5wKPAme3+24EPgzsAn5I+9j2qtqX5GLgzrbvovYhi5KkKRgsHFX1T8z9+gTAqXPsL+C8g/ysbcC2wzedJOn18p3jkqQuhkOS1MVwSJK6GA5JUhfDIUnqYjgkSV0MhySpi+GQJHUxHJKkLoZDktTFcEiSuhgOSVIXwyFJ6mI4JEldDIckqYvhkCR1MRySpC6GQ5LUxXBIkroYDklSF8MhSepiOCRJXQyHJKmL4ZAkdTEckqQuhkOS1MVwSJK6GA5JUhfDIUnqYjgkSV0MhySpi+GQJHUxHJKkLoZDktTFcEiSugwWjiTbkuxJct/Y2nFJdiZ5uH0/tq0nyZeS7Epyb5L3jz1mS9v/cJItQ80rSZrMkGccVwEbX7V2PnBzVa0Dbm7HAGcA69rXVuCrMAoNcCHwAeAk4MIDsZEkTcdg4aiqbwP7XrW8Cdjebm8Hzhxbv7pGvgMck+R44HRgZ1Xtq6qngZ28NkaSpAW00K9xvL2qngBo39/W1lcDj43t293WDrYuSZqSxfLieOZYq3nWX/sDkq1JZpPM7t2797AOJ0l62UKH48n2FBTt+562vhs4YWzfGuDxedZfo6quqKoNVbVhZmbmsA8uSRpZ6HDcABy4MmoLcP3Y+jnt6qqTgWfbU1k3AaclOba9KH5aW5MkTcnKoX5wkq8DHwJWJdnN6OqozwHXJjkXeBQ4u22/EfgwsAv4IfApgKral+Ri4M6276KqevUL7pKkBTRYOKrqEwe569Q59hZw3kF+zjZg22EcTZL0/7BYXhyXJC0RhkOS1MVwSJK6GA5JUhfDIUnqYjgkSV0MhySpi+GQJHUxHJKkLoZDktTFcEiSuhgOSVIXwyFJ6mI4JEldDIckqYvhkCR1MRySpC6GQ5LUxXBIkroYDklSF8MhSepiOCRJXQyHJKmL4ZAkdTEckqQuhkOS1MVwSJK6GA5JUhfDIUnqYjgkSV0MhySpy8ppDyCpz6MX/cK0R9Ai9DN/+t0F+7M845AkdTEckqQuhkOS1GXJhCPJxiQPJdmV5PxpzyNJy9WSCEeSFcDlwBnAeuATSdZPdypJWp6WRDiAk4BdVfVIVf0PsAPYNOWZJGlZWirhWA08Nna8u61JkhbYUnkfR+ZYq1dsSLYCW9vh80keGnyq5WMV8NS0h1gMcumWaY+gV/Lf5gEXzvWfyW4/O8mmpRKO3cAJY8drgMfHN1TVFcAVCznUcpFktqo2THsO6dX8tzkdS+WpqjuBdUlOTHIUsBm4YcozSdKytCTOOKpqf5LfAW4CVgDbqur+KY8lScvSkggHQFXdCNw47TmWKZ8C1GLlv80pSFUdepckSc1SeY1DkrRIGA7NK8nPJ/mXJC8k+YNpzyMBJNmWZE+S+6Y9y3JkOHQo+4DfAy6d9iDSmKuAjdMeYrkyHJpXVe2pqjuB/532LNIBVfVtRv9ToykwHJKkLoZDktTFcOg1kpyX5J729c5pzyNpcVkybwDUwqmqyxn9/hNJeg3fAKh5JXkHMAscDfwYeB5YX1XPTXUwLWtJvg58iNGn4z4JXFhVV051qGXEcEiSuvgahySpi+GQJHUxHJKkLoZDktTFcEiSuhgOSVIXwyFJ6mI4JEld/g8OPzBKvW6z0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import libraries for plotting class distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "high_quality_ratio = len(data.target[data.target==1])/len(data.target)\n",
    "print('Percentage of high quality observations', high_quality_ratio)\n",
    "\n",
    "# color coding for 2 classes\n",
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "\n",
    "## code to plot the class distribution. Hint: countplot in seaborn\n",
    "sns.countplot(data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** When classes are imbalanced, we are likely to get suprisingly good accuracy score for any model because it minimizes the error rate by predicting the majority class. However, the model is useless because our goal often is to detect the minority class. So the metric we care about - the recall rate would be low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing a Random Forest classfier directly on the data (3pts)\n",
    "\n",
    "Let's first train a random forest classifier with default parameters using X_train and y_train and test the performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier accuray: 0.9485714285714286\n",
      "Random forest classifier recall: 0.09090909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # class for random forest classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "## Instantiate and fit a random forest classifier to the training data\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "## Measure and print out the accuracy and recall\n",
    "test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "\n",
    "print('Random forest classifier accuray:', test_acc)\n",
    "\n",
    "test_recall = recall_score(y_test,clf.predict(X_test))\n",
    "\n",
    "print('Random forest classifier recall:', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quetion:** Compute the recall and accuracy scores of the random forest classifier. How is the gap between the accuracy and recall scores? Provide an explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** The accuracy is really high, and the recall rate is really low. There is a huge gap because the model likely predicted the majority class for most of the input. However, recall is the ratio of correctly predicted positive observations to the all observations in actual class. (https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/) The model is not sensitive in picking out the high quality wines that we care about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data balancing via Smote (6pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of high quality counts in the balanced data:0.5%\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE #Over sampling\n",
    "import numpy as np\n",
    "\n",
    "## Instantiate smote and balance training data only\n",
    "smote = SMOTE()\n",
    "X_res,y_res = smote.fit_resample(X_train,y_train)\n",
    "## Compute and print percentage of high quality wine after balancing\n",
    "percentage = len(y_res[y_res == 1])/len(y_res)\n",
    "print('Percentage of high quality counts in the balanced data:{}%'.format(percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Plot the distribution of balanced training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1f73e390>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "## plot the class distribution of training data after balanced\n",
    "sns.countplot(y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrain and test our random forest model on the balanced training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier accuray: 0.9395918367346939\n",
      "Random forest classifier recall: 0.25757575757575757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Instantiate random forest and train on balanced training data\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_res,y_res)\n",
    "test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "\n",
    "print('Random forest classifier accuray:', test_acc)\n",
    "\n",
    "test_recall = recall_score(y_test,clf.predict(X_test))\n",
    "\n",
    "print('Random forest classifier recall:', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Compute the recall and accuracy scores of the new random forest classifier. How do the accuracy and recall change compared to those without data balancing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** The recall rate is almost 3 times higher as accuracy remains high. However the value of recall is still low. Since now we have a balanced dataset, we should switch the focus to tweaking the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control complexity of the model (18pts)\n",
    "\n",
    "#### Control the depth of decision trees in our ensemble (6pts)\n",
    "By default, the decision trees in random forest are expanded until all leaves are pure or until all leaves contain less than a certain number set by min_samples_split parameter. Let's try a fixed maximum depth that the tree can expand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier accuray: 0.8130612244897959\n",
      "Random forest classifier recall: 0.5454545454545454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## Instantiate model with max depth trees being 3\n",
    "clf = RandomForestClassifier(max_depth = 3)\n",
    "clf.fit(X_res,y_res)\n",
    "\n",
    "test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "\n",
    "print('Random forest classifier accuray:', test_acc)\n",
    "\n",
    "test_recall = recall_score(y_test,clf.predict(X_test))\n",
    "\n",
    "print('Random forest classifier recall:', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Compute the recall and accuracy scores of the new random forest classifier. How do the accuracy and recall change compared to those in the default parameter case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** After we limited the max_depth, the accuracy was lower by about 12%, as the recall went up by about 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the number of trees in the forest (6pts)\n",
    "By default, we use 10 random trees. Let's increase this number to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier accuray: 0.833469387755102\n",
      "Random forest classifier recall: 0.5909090909090909\n"
     ]
    }
   ],
   "source": [
    "## Instantiate model with max depth of 3 and 100 decision trees\n",
    "\n",
    "clf = RandomForestClassifier(max_depth = 3,n_estimators = 100)\n",
    "clf.fit(X_res,y_res)\n",
    "\n",
    "test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "\n",
    "print('Random forest classifier accuray:', test_acc)\n",
    "\n",
    "test_recall = recall_score(y_test,clf.predict(X_test))\n",
    "\n",
    "print('Random forest classifier recall:', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Compute the recall and accuracy scores of the random forest classifier. How do the accuracy and recall change compared to those with 10 trees? What do the results imply about increasing the number of trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Both accuracy and recall went up. Since random forest is essencially bagging, having more trees means the ensembled model taking average over more randomized trees, so it performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree pruning by min_impurity_decrease (6pts)\n",
    "By default, the tree keeps expanding until the impurity is 0. However, we can specify a minimum impurity decrease amount under which nodes in the tree stop branching. RandomForestClassifier in sklearn use min_impurity_decrease for setting this threshold. Let's try that on our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier accuracy: 0.843265306122449\n",
      "Random forest classifier recall: 0.5909090909090909\n"
     ]
    }
   ],
   "source": [
    "## Instantiate model with min impurity decrease of 0.001\n",
    "\n",
    "clf = RandomForestClassifier(max_depth = 3,n_estimators = 100,min_impurity_decrease = 0.001)\n",
    "clf.fit(X_res,y_res)\n",
    "\n",
    "test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "\n",
    "print('Random forest classifier accuracy:', test_acc)\n",
    "\n",
    "test_recall = recall_score(y_test,clf.predict(X_test))\n",
    "\n",
    "print('Random forest classifier recall:', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Compute the recall and accuracy scores of the random forest classifier. How does the recall change compared to those with 10 trees and max_depth = 3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** The accurcay and recall didn't change much when we specify a minimum impurity decrease. This might be because the threshold is still close to 0, or setting up max_depth already prevents the trees branching out too deep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "5yX9Z",
   "launcher_item_id": "eqnV3",
   "part_id": "Msnj0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
