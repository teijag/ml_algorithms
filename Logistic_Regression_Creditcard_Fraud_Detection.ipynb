{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for Credit Card Fraud Detection (10 pts)\n",
    "\n",
    "Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` as well as `Amount` which is the amount of the transaction. \n",
    " \n",
    "The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data (1 pts)\n",
    "Load the data from `fraud_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of fraud: 1.6410823768035772 %\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"fraud_data.csv\")\n",
    "\n",
    "## Print the percentage of fraud observations\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Your code here\n",
    "print (\"The percentage of fraud:\", len(y[y==1])/len(y)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What percentage of the observations in the dataset are instances of fraud?\n",
    "\n",
    "The percentage of fraud observation is 1.64%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions using the majority class label (4pts)\n",
    "\n",
    "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? (Here accuracy is the ratio of the number of correctly classified transactions to the total number of transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier accuray: 0.9852507374631269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "    \n",
    "## Instantiate and fit a dummy classifier that always predict class label by the majority class of the training data\n",
    "## Use DummyClassifier in sklearn with strategy 'most_frequent\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train,y_train)\n",
    "dummy_test_pred = dummy.predict(X_test)\n",
    "\n",
    "## Measure test accuracy of your dummy classifier\n",
    "dummy_test_acc = dummy.score(X_test,y_test)\n",
    "\n",
    "print('Dummy classifier accuray:', dummy_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *How does the accuracy of the dummy classifier look (very low, low, high, very high)? Give an explanation.*\n",
    "\n",
    "The accuracy of the dummy classifier looks very high as it\\'s getting to 100% accuracy rate. However, there're only 1.64% fraud observations in the dataset. This model missed all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *How many fraudulent transactions are correctly classified? (This is the **recall** score/measure)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "## Measure test recall score of your dummy classifier\n",
    "dummy_test_recall = recall_score(y_test,dummy_test_pred)\n",
    "\n",
    "print('Dummy classifier recall:', dummy_test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *How does the recall of the dummy classifier look (very low, low, high, very high)? Give an explanation.*\n",
    "\n",
    "The recall rate is very low as it's 0.0. The model didn't correctly classified any fraud observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a logistic regression model (3pts)\n",
    "\n",
    "Train a logisitic regression classifier with default parameters using X_train and y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic classifier accuray: 0.9963126843657817\n",
      "Logistic classifier recall: 0.775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "## Instantiate a logistic regression model and fit to the training data\n",
    "logR = LogisticRegression()\n",
    "logR.fit(X_test,y_test)\n",
    "logR_test_pred = logR.predict(X_test)\n",
    "\n",
    "## Measure test accuracy \n",
    "logR_test_acc = logR.score(X_test,y_test)\n",
    "\n",
    "print('Logistic classifier accuray:', logR_test_acc)\n",
    "\n",
    "## Measure test recall\n",
    "logR_test_recall = recall_score(y_test,logR_test_pred)\n",
    "\n",
    "print('Logistic classifier recall:', logR_test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *Compare the results of logistic regression with those of the above dummy classifier*\n",
    "\n",
    "The logistic regression achieves higher accuracy as well as recall rate than the dummy classifier. It found 77.5% of fraudulent observations, and misclassified the rest of the 1.64% of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for selecting hyperparameters for Logistic Regression (2pts)\n",
    "\n",
    "Perform a grid search over the parameters listed below for a Logisitic Regression classifier, using recall for scoring and the default 3-fold cross validation.\n",
    "\n",
    "`'penalty': ['l1', 'l2']`\n",
    "\n",
    "`'C':[0.01, 0.1, 1, 10, 100]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic classifier accuray: 0.8\n",
      "Logistic classifier recall: 0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## Define the grid of logistic regression parameters\n",
    "parameters = [{'penalty': ['l1', 'l2'],'C':[0.01, 0.1, 1, 10, 100]}]\n",
    "model = LogisticRegression()\n",
    "    \n",
    "## Perform grid search CV to find best model parameter setting\n",
    "cmodel = GridSearchCV(model,param_grid = parameters,scoring='recall',cv=3)\n",
    "cmodel.fit(X_train, y_train.ravel())\n",
    "\n",
    "## Fit logistic regression with best parameters to the entire training data\n",
    "model = cmodel\n",
    "    \n",
    "logR_test_pred = model.predict(X_test)\n",
    "\n",
    "## Measure test accuracy\n",
    "logR_test_acc = model.score(X_test,y_test)\n",
    "\n",
    "print('Logistic classifier accuray:', logR_test_acc)\n",
    "\n",
    "## Measure test recall\n",
    "logR_test_recall = recall_score(y_test,logR_test_pred)\n",
    "\n",
    "print('Logistic classifier recall:', logR_test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *Compare the results with that of logistic regression with default parameters*\n",
    "\n",
    "The accuracy is lower than the logistic model but the recall is higher. Since we chose recall as our scoring method for grid search, the parameters combination optimizes the recall rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "5yX9Z",
   "launcher_item_id": "eqnV3",
   "part_id": "Msnj0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
