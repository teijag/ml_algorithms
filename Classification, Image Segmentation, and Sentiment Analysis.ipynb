{
 "cells": [
 
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Email spam classification [50 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Get the data from: http://www.andrew.cmu.edu/user/georgech/preprocessed-enron-email-dataset.zip\n",
    "   - Unzip this into the same folder as this notebook, rename it to `email-data`\n",
    "   - The folder contains 3 subfolders:\n",
    "      - `ham` contains ham emails.\n",
    "      - `spam` contains spam emails.\n",
    "      - `testing` is a folder containing test emails for your classifier. The ham/spam label is in the filename.\n",
    "      \n",
    "**Important**: For this problem, do *not* use neural nets/deep nets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Print the number of ham and spam emails [1 point]\n",
    " \n",
    "In addition to providing the code, respond to the following questions:\n",
    "\n",
    "   - Is this dataset imbalanced? Will this be problematic in training the model?\n",
    "   - If so, how would you address it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Construct the documents [4 points]\n",
    " \n",
    "   - Provided below is a function that returns a document present in a file given a fileName.\n",
    "   - The function performs some preprocessing to (1) remove punctuation, (2),(3) remove whitespace and (4) lowercase all words.\n",
    "   - Use this function to construct a list of documents.\n",
    "   - Also construct a list of document labels containing `1` for spam and `0` for ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import codecs\n",
    "\n",
    "def makeWordList(path):\n",
    "    \n",
    "    with codecs.open(path, \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "        corpus_text = f.read()\n",
    "\n",
    "    for c in string.punctuation:\n",
    "        corpus_text = corpus_text.replace(c, \"\")  # -- (1)\n",
    "    \n",
    "    text = re.sub(r'\\S*\\d\\S*','',corpus_text) # -- (2)\n",
    "    text = re.sub(r'[^\\w\\s]','',text)         # -- (3)\n",
    "    \n",
    "    text = text.lower().split()           # -- (4)         \n",
    "    \n",
    "    li = []\n",
    "    for token in text:\n",
    "        li.append(token)\n",
    "\n",
    "    return \" \".join(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Construct the document matrix `X` as a matrix of word frequencies [5 points]\n",
    "\n",
    "   - Use the `CountVectorizer` from scikit-learn.\n",
    "   - Set `min_df=50`; this drops words that don't occur in at least 50 documents.\n",
    "   - Set `stop_words=\"english\"` and `max_df=0.8` to filter out stop-words.\n",
    "   - Print the size of the vocabulary (number of unique words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) k-NN, SVM, random forest: Hyperparameter selection [20 points]\n",
    "\n",
    "Now that you have your documents and labels as training data, you can perform 5-fold cross-validation to select the hyperparameters for different learning algorithms.\n",
    "\n",
    "The hyperparameter with the best performance averaged across 5 folds is chosen. Use the **weighted F1-score** as the evaluation metric (i.e., for the `f1_score` function imported from `sklearn.metrics`, be sure to use the parameter `average='weighted'`).\n",
    "\n",
    "   - k-NN: Select `k` from a range of values of your choice.\n",
    "   - SVM: (SVC) Select `C` from a range of your choice, use any kernel that performs well.\n",
    "   - Random forest: Select `n_estimators` **and** `max_depth` from a grid of your choice.\n",
    "\n",
    "Store each chosen hyperparameter as `best_k`, `best_C`, `best_n_estimators`, and `best_max_depth` respectively.\n",
    "\n",
    "Provided is some seed code for cross-validation that you may modify and reuse. Do not use the cross-validations score or grid-search functions from scikit-learn (you may use `KFold`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "num_folds = 5\n",
    "k_fold = KFold(num_folds)\n",
    "hyperparameter_settings = []  # fill this with hyperparameter settings that you want to try\n",
    "\n",
    "best_hyperparam_setting = None\n",
    "best_cross_val_score = -np.inf  # assumes that a higher score is better\n",
    "for hyperparam_setting in hyperparameter_settings:\n",
    "    fold_scores = []\n",
    "    # your code to train and score the training data here\n",
    "    \n",
    "    cross_val_score = np.mean(fold_scores)\n",
    "    if cross_val_score > best_cross_val_score:  # assumes that a higher score is better\n",
    "        best_cross_val_score = cross_val_score\n",
    "        best_hyperparam_setting = hyperparam_setting\n",
    "\n",
    "print('Best hyperparameter setting:', best_hyperparam_setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Classifier testing: Precision-Recall and ROC curves [20 points]\n",
    "\n",
    "   - Use the best hyperparameters for each classifier from the previous question to **train** your classifiers on the training data.\n",
    "   - Use test emails to in the `testing` folder to **test** your classifiers and construct the plots below.\n",
    "\n",
    "Things to plot:\n",
    "\n",
    "   - Construct one plot containing 3 ROC curves, one for each classifier.\n",
    "   - In the legend of this plot, display the AUC for each classifier.\n",
    "   - Construct one plot containing 3 precision-recall curves, one for each classifier.\n",
    "   - In the legend of each plot, display the average precision for each classifier.\n",
    "\n",
    "Note that these plots are on the test data: you will have to read in this data, construct a document matrix and labels. Some words in the test data may not have been present in the training data: there are multiple ways to address this, briefly describe your approach.\n",
    "\n",
    "Things to answer:\n",
    "\n",
    "   - Of the ROC and Precision-Recall curves, which one would you use for this task and why?\n",
    "   - Which classifier is the best, according to your chosen curves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Image Segmentation [50 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is segmentation?\n",
    "\n",
    "Segmentation is the task of \"labeling\" groups of pixels in an image to identify certain objects.\n",
    "\n",
    "In the early years, research on segmentation was focused on \"foreground-background\" segmentation; marking only those pixels that comprise the \"background\" of an image (in the image below, the background is marked in blue).\n",
    "\n",
    "<div>\n",
    "<img src=\"http://www.eyeshalfclosed.com/images/cat.jpg\" width=500/>\n",
    "</div>\n",
    "\n",
    "In recent years, sophisticated deep-learning models have enabled complex multi-label segmentation, such as in the images below.\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"http://www.eyeshalfclosed.com/images/sheep.png\" width=500/>\n",
    "</td>\n",
    "<td>\n",
    "<img src=\"http://www.eyeshalfclosed.com/images/street.png\" width=500/>\n",
    "</td>\n",
    "</tr>\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Prerequisites [20 points]\n",
    "\n",
    "You get 20 points for setting up AWS and successfully running the code given in the following sections.\n",
    "\n",
    "This homework needs to be run on an AWS GPU instance; it will not complete in time without a GPU. Look up the relevant documentation to set up an AWS machine as configured below.\n",
    "\n",
    "**Machine.**\n",
    "\n",
    "   - Use the [Ubuntu Deep Learning AMI](https://aws.amazon.com/marketplace/pp/B077GCH38C).\n",
    "   - Use a p2.xlarge instance.\n",
    "   - Allocate at least 80GB of disk space.\n",
    "   - Use the `conda_tensorflow_p36` Conda environment: `source activate tensorflow_p36`\n",
    "   - Create a security group and open all inbound/outbound ports to 0.0.0.0/0.\n",
    "\n",
    "All commands below assume the aforementioned Conda environment is active.\n",
    "\n",
    "**Run Jupyter.** `jupyter notebook --ip=* --no-browser`\n",
    "\n",
    "You may move Jupyter to the background by: CTRL-Z, then `bg`, then `disown`. You can access Jupyter using your public DNS; it will look something like `ec2-54-84-36-171.compute-1.amazonaws.com:8888`. Figure out how you can find this out.\n",
    "\n",
    "**Data downloads.** All downloads must go into the same directory as this notebook. Unzip files after download. *This will take time.*\n",
    "\n",
    "   * Download the [trained model weights](https://github.com/matterport/Mask_RCNN/releases/download/v1.0/mask_rcnn_coco.h5) (~250MB).\n",
    "\n",
    "   * Download the [training images](http://images.cocodataset.org/zips/train2014.zip) (13GB).\n",
    "   \n",
    "   * Download the [validation images](http://images.cocodataset.org/zips/val2014.zip) (6GB).\n",
    "   * Download the [training image annotations](https://dl.dropboxusercontent.com/s/o43o90bna78omob/instances_minival2014.json.zip?dl=0).\n",
    "   * Download the [test image annotations](https://dl.dropboxusercontent.com/s/s3tw5zcg7395368/instances_valminusminival2014.json.zip?dl=0).\n",
    "\n",
    "Now create a new folder named `2014`, then move the `train2014`, `val2014` folders into `2014/`.\n",
    "\n",
    "Create a new `2014/annotations/` folder and move the train and test annotation JSON files into it\n",
    "\n",
    "Your directory structure should look like:\n",
    "```\n",
    "2014/\n",
    "   /annotations/\n",
    "       /annotations/instances_minival2014.json\n",
    "       /annotations/instances_valminusminival2014.json\n",
    "   /train2014/\n",
    "       /train2014/*.jpg\n",
    "   /val2014/\n",
    "       /val2014/*.jpg\n",
    "```\n",
    "\n",
    "**Package installation.**\n",
    "\n",
    "   * Install Cython: `pip install cython`\n",
    "   * Install Tensorflow: `pip install tensorflow tensorflow-gpu`\n",
    "   * Install Keras and image tools: `pip install keras scikit-image pillow h5py`\n",
    "   * Install OpenCV: `pip install opencv-python`\n",
    "   * Install pycoco:\n",
    "   \n",
    "`pip install \"git+https://github.com/philferriere/cocoapi.git#egg=pycocotools&subdirectory=PythonAPI\"`\n",
    "   \n",
    "**GPU.** Ensure Keras/TensorFlow can see your GPU with the following Python code (run in the `conda_tensorflow_p36 environment` after installing all the required packages). You should see a GPU in one of the devices listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a pre-trained model on small data\n",
    "\n",
    "We will first load a pre-trained convolutional neural network model and test it on a small dataset of images. These images are stored in the `/images/` folder.\n",
    "\n",
    "The model was trained by annotating each image with the objects it contains. Annotations are in the following format:\n",
    "\n",
    "```\n",
    "annotation{\n",
    "    \"id\" : int,\n",
    "    \"image_id\" : int,\n",
    "    \"category_id\" : int,\n",
    "    \"segmentation\" : RLE or [polygon],\n",
    "    \"area\" : float,\n",
    "    \"bbox\" : [x,y,width,height],\n",
    "    \"iscrowd\" : 0 or 1,\n",
    "}\n",
    "\n",
    "categories[{\n",
    "    \"id\" : int,\n",
    "    \"name\" : str,\n",
    "    \"supercategory\" : str,\n",
    "}]\n",
    "```\n",
    "\n",
    "Make sure you understand the annotations and how they are connect to images by looking at [section 4 on this page](http://cocodataset.org/#download). You may ignore the `iscrowd` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import coco\n",
    "import utils\n",
    "import model as modellib\n",
    "from model import log\n",
    "import visualize\n",
    "from config import Config\n",
    "from shapes import ShapesDataset\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model configuration\n",
    "\n",
    "These lines specify how many GPUs to use, and how many images to process in parallel on each GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "#config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pre-trained model\n",
    "\n",
    "This is actually a Keras model wrapped along with some helpful functions. The model may be loaded in two modes: `training` and `inference` (testing) mode. `model_dir` points towards a directory to save logs and trained weights, which we have set above as the `/logs` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard-code object classes\n",
    "\n",
    "For the small dataset of images we are using, we define our own list of class names and class indices for each object. These are of various types: for example, \"car\", \"bicycle\", etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize a random image\n",
    "\n",
    "Make sure you understand what the code below is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_names = next(os.walk(IMAGE_DIR))[2]\n",
    "image = skimage.io.imread(os.path.join(IMAGE_DIR, random.choice(file_names)))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the pre-trained model\n",
    "\n",
    "We now call the `detect` function of the model on the list of images we want to be segmented. This returns a `result` object; inspect this object to see what it contains.\n",
    "\n",
    "The `visualize` helper module provides useful functions to visualize our segmentation results. Understand how this function works (SHIFT+TAB in Jupyter is useful, as well as looking at the code in `visualize.py` directly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results = model.detect([image], verbose=1)\n",
    "r = results[0]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            class_names, r['scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training from scratch\n",
    "\n",
    "Now that we understand what a properly trained model should do, we consider training a model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "Load the annotations for the training images into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "config = coco.CocoConfig()\n",
    "COCO_DIR = \"2014\"\n",
    "dataset = coco.CocoDataset()\n",
    "dataset.load_coco(COCO_DIR, \"minival\")\n",
    "dataset.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the same for the test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset_val = coco.CocoDataset()\n",
    "dataset_val.load_coco(COCO_DIR, \"val35k\")\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List a few object classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Image Count: {}\".format(len(dataset.image_ids)))\n",
    "print(\"Class Count: {}\".format(dataset.num_classes))\n",
    "for i, info in enumerate(dataset.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a random image and its annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load random image and mask.\n",
    "image_id = random.choice(dataset.image_ids)\n",
    "image = dataset.load_image(image_id)\n",
    "mask, class_ids = dataset.load_mask(image_id)\n",
    "bbox = utils.extract_bboxes(mask)\n",
    "\n",
    "# Display image and additional stats\n",
    "print(\"image_id \", image_id, dataset.image_reference(image_id))\n",
    "log(\"image\", image)\n",
    "log(\"mask\", mask)\n",
    "log(\"class_ids\", class_ids)\n",
    "log(\"bbox\", bbox)\n",
    "\n",
    "# Display image and instances\n",
    "visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training configuration\n",
    "\n",
    "See the default configuration values in `config.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    STEPS_PER_EPOCH = 60\n",
    "\n",
    "config = TrainConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Create a new model in training mode [5 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Initialize the model weights with the weights learned on COCO [5 points]\n",
    "\n",
    "Call `load_weights` as before, but add the following argument in the call to the function:\n",
    "\n",
    "```\n",
    "exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "          \"mrcnn_bbox\", \"mrcnn_mask\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Train the model for 10 epochs [5 points]\n",
    "\n",
    "Look up the documentation or code for the train function to figure out its arguments.\n",
    "\n",
    "Pass the following additional arguments to the `train` function:\n",
    "\n",
    "   - `layers=\"heads\"` to only train the weights that were not pre-loaded.\n",
    "   - `learning_rate=config.LEARNING_RATE` to set the learning rate.\n",
    "   - `epochs=10`.\n",
    "   \n",
    "This will take ~10 minutes on a p2.xlarge GPU instance with 1 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# call to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Visualize learning progress with TensorBoard [5 points]\n",
    "\n",
    "   - Start Tensorboard (in a terminal) with `tensorboard --logdir=logs/` in the same folder as the notebook:\n",
    "```\n",
    "TensorBoard 0.1.8 at http://ip-172-31-27-18:6006 (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "   - Connect to (in a web browser) `public_dns:6006` where `public_dns` is your public DNS (this is the address of your AWS machine).\n",
    "   - Click on the \"Scalars\" tab at the top of the page.\n",
    "   - Include a screenshot of the overall loss vs. number of epochs below this line (store the image in the same folder as the notebook as \"yourloss.png\"). **Important: When you submit your HW3, it should include `yourloss.png`.**\n",
    "   \n",
    " <img src=\"yourloss.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Test model [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model in inference (testing) mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the last trained model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = model.find_last()[1] # use the last trained weights\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the true annotations of a random test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_bbox)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the predicted annotations for this image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction function call and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Sentiment Analysis [50 points]\n",
    "\n",
    "Download data from: http://www.andrew.cmu.edu/user/georgech/HW3-data.zip <br>\n",
    "\n",
    "The folder contains:\n",
    "\n",
    "- train.csv\n",
    "- test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Read the training data  [5 Points]\n",
    "\n",
    "Read the data present in train.csv file. **Please do no change the file name. In particular, use a relative path, i.e., './HW3-data/train.csv'** <br>\n",
    "Perform the following cleaning on the data:\n",
    "1. Keep only the sentiment and sentiment text in the data - the first and the last coumn\n",
    "2. Shuffle the rows of the data frame such that the positive and negative tweets are mixed\n",
    "3. Print the first 5 sentiments.\n",
    "4. Print the number of positive and negative sentiment labels\n",
    "Note: If you are using `open()`, you may have to set `encoding='iso8859'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Data Preparation [7 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building a neural network model, we first need to prepare the data. The input to a RNN model  is a matrix with shape (a, b), where a is the number of samples (tweets), and b is the sequence length of each tweet. Prepare the data with the following steps:\n",
    "\n",
    "1\\. Take the RAW texts of the top 5000 tweets in the data and convert them to a list of strings, where each string is a tweet. [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Use `Tokenizer` from `keras.preprocessing.text` to tokenize the texts and convert them to sequences (numbers) with the `texts_to_sequences` method of `Tokenizer`. **When tokenizing, please only consider the top 10,000 words in the dataset (`num_words`=10,000)**. [4 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Use `pad_sequences` from `keras.preprocessing.sequence` to pad each sequence with zeros to **make the sequence length 120**. [2 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  (c) Simple RNN [20 points]\n",
    "\n",
    "i) [8 points] Build a simple RNN model with the following specification:\n",
    "1. An embedding layer with output dimenstion 64.\n",
    "2. A simple RNN layer.\n",
    "3. A dense layer with sigmoid activation function for prediction.\n",
    "Print the summary of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) [12 points] Now train the simple RNN model:\n",
    "\n",
    "1\\. Compile the model with binary cross entory as loss and accuracy as evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Fit the model with the training set with 5 epochs (use 20% of the data as validation). Play with the batch size to find a value that seems to work well (for example, you may find a smaller choice like 32 to result in extremely slow learning; try larger values like 512, 1024, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Plot the training and validation accuracy across epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) LSTM [4 points] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) [2 point] Now built a LSTM model by replacing the simple RNN layter in the above model with a LSTM layer. Print a summary of the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) [2 point] Train the LSTM model with the same specifications in the simple RNN model. Again, plot the training and validation accuracy across epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Evaluation on test data [14 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) [5 points] Using the simple RNN and LSTM models from the previous parts (do *not* retrain these using the full training dataset; it's fine to use the same models you learned from before where technically 20% of the training data were held out as validation data), evaluate their performance on the *test* set (`test.csv`). What are the test set raw accuracies that you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) [9 points] In the previous models, we only use the top 5000 tweets. Now train the LSTM-based model using the whole training dataset. Again use 20% of the training dataset as validation. After learning the model, test it on the true test set. What is the test set raw accuracy that you get? How does this test set accuracy compare to the validation accuracy, and to the test set accuracy you got from using only 5000 tweets (or technically 5000\\*0.8=4000 tweets to train)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
